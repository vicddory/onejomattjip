# -*- coding: utf-8 -*-
"""
================================================================================
ğŸ“ views/tab4_news.py - ê¸€ë¡œë²Œ & ë¡œì»¬ ì»¤í”¼ ë‰´ìŠ¤ ì¸ì‚¬ì´íŠ¸ (Optimized v2)
================================================================================
Google RSSì™€ ë„¤ì´ë²„ APIë¥¼ í™œìš©í•œ ì»¤í”¼ ê´€ë ¨ ë‰´ìŠ¤ ìˆ˜ì§‘ ë° ë¶„ì„
- ë³‘ë ¬ ì²˜ë¦¬ë¥¼ í†µí•œ ì„±ëŠ¥ ìµœì í™”
- ì‹¤ì‹œê°„ ì§„í–‰ë¥  í‘œì‹œ
- ì´ë¯¸ì§€ ì œê±° ë° í…ìŠ¤íŠ¸ ì¤‘ì‹¬ ê¹”ë”í•œ ë ˆì´ì•„ì›ƒ
- ê¸€ë¡œë²Œ ë¦¬ìŠ¤í¬ íƒ­ ë²„ê·¸ ìˆ˜ì •
================================================================================
"""

import streamlit as st
import feedparser
import requests
import re
import matplotlib.pyplot as plt
from wordcloud import WordCloud
from textblob import TextBlob
from deep_translator import GoogleTranslator
from newspaper import Article, Config
import nltk
from concurrent.futures import ThreadPoolExecutor, as_completed
from typing import List, Dict, Optional
import time

# ê²½ë¡œ ì„¤ì •
import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from config import NAVER_CLIENT_ID, NAVER_CLIENT_SECRET

# NLTK ë°ì´í„° ë‹¤ìš´ë¡œë“œ (ìµœì´ˆ 1íšŒ)
try:
    nltk.data.find('tokenizers/punkt')
except LookupError:
    nltk.download('punkt', quiet=True)


# ===========================================
# ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜
# ===========================================
@st.cache_resource
def get_translator():
    return GoogleTranslator(source='auto', target='ko')


def translate_text(text: str) -> str:
    """í…ìŠ¤íŠ¸ë¥¼ í•œêµ­ì–´ë¡œ ë²ˆì—­"""
    try:
        if not text:
            return ""
        translator = get_translator()
        return translator.translate(text[:4999])
    except Exception as e:
        return text


def get_article_config() -> Config:
    """newspaper3k Config ê°ì²´ ìƒì„± (ë´‡ íƒì§€ íšŒí”¼)"""
    config = Config()
    config.browser_user_agent = 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
    config.request_timeout = 3
    config.MAX_TEXT = 200000
    return config


def analyze_sentiment(text: str) -> str:
    """ê°ì„± ë¶„ì„"""
    try:
        blob = TextBlob(text)
        score = blob.sentiment.polarity
        if score > 0.1:
            return "ğŸŸ¢ ê¸ì •ì "
        elif score < -0.1:
            return "ğŸ”´ ë¶€ì •ì "
        return "âšª ì¤‘ë¦½ì "
    except:
        return "âšª ì¤‘ë¦½ì "


def display_wordcloud(news_list: List[Dict]):
    """ì›Œë“œí´ë¼ìš°ë“œ í‘œì‹œ"""
    if not news_list:
        return
    text = " ".join([item.get('ì›ì œ', '') for item in news_list])
    if not text.strip():
        return
    
    try:
        wc = WordCloud(
            width=800, 
            height=400, 
            background_color='white', 
            colormap='copper', 
            max_words=80
        ).generate(text)
        fig, ax = plt.subplots(figsize=(10, 5))
        ax.imshow(wc, interpolation='bilinear')
        ax.axis('off')
        st.pyplot(fig)
        plt.close(fig)
    except Exception as e:
        st.warning(f"ì›Œë“œí´ë¼ìš°ë“œ ìƒì„± ì‹¤íŒ¨: {str(e)}")


# ===========================================
# ë³‘ë ¬ ì²˜ë¦¬ í•¨ìˆ˜
# ===========================================
def process_single_news(entry: Dict, target_keywords: Optional[List[str]], 
                       coffee_guard_terms: List[str]) -> Optional[Dict]:
    """ê°œë³„ ë‰´ìŠ¤ í•­ëª© ì²˜ë¦¬ (ë³‘ë ¬ ì‹¤í–‰ìš©)"""
    try:
        title_en = entry.title
        link = entry.link
        summary_text = entry.get('summary', '')
        content_to_check = (title_en + " " + summary_text).lower()
        
        # í‚¤ì›Œë“œ í•„í„°ë§
        if target_keywords:
            has_target = any(k.lower() in content_to_check for k in target_keywords)
            has_coffee_context = any(term in content_to_check for term in coffee_guard_terms)
            if not (has_target and has_coffee_context):
                return None
        
        # ê°ì„± ë¶„ì„ ë° ë²ˆì—­
        sentiment = analyze_sentiment(title_en)
        korean_title = translate_text(title_en)
        
        return {
            "ì œëª©": korean_title,
            "ì›ì œ": title_en,
            "ë§í¬": link,
            "ê²Œì‹œì¼": entry.get('published', '')[:16],
            "ê°ì„±": sentiment
        }
    except Exception as e:
        return None


@st.cache_data(ttl=600)
def fetch_google_news(query: str, target_keywords: Optional[List[str]] = None, 
                     period: str = '30d') -> List[Dict]:
    """Google RSSë¡œ í•´ì™¸ ë‰´ìŠ¤ ìˆ˜ì§‘ (ë³‘ë ¬ ì²˜ë¦¬ + ìºì‹±)"""
    noise_filter = "-Starbucks -store -closing -travel -hotel"
    full_query = f"{query} {noise_filter}"
    encoded_query = full_query.replace(" ", "%20")
    rss_url = f"https://news.google.com/rss/search?q={encoded_query}+when:{period}&hl=en-US&gl=US&ceid=US:en"
    
    try:
        feed = feedparser.parse(rss_url)
    except Exception as e:
        return []

    if not feed.entries:
        return []

    coffee_guard_terms = ["coffee", "bean", "arabica", "robusta", "commodity", 
                         "harvest", "crop", "farm", "export", "price", "supply"]
    
    news_list = []
    seen_titles = set()
    
    # ë³‘ë ¬ ì²˜ë¦¬
    with ThreadPoolExecutor(max_workers=10) as executor:
        futures = []
        for entry in feed.entries[:100]:
            title_signature = entry.title[:30].lower()
            if title_signature not in seen_titles:
                seen_titles.add(title_signature)
                futures.append(
                    executor.submit(process_single_news, entry, target_keywords, coffee_guard_terms)
                )
        
        for future in as_completed(futures):
            result = future.result()
            if result:
                news_list.append(result)
            if len(news_list) >= 30:
                break
    
    return news_list[:30]


# ===========================================
# ë„¤ì´ë²„ ë‰´ìŠ¤ API (êµ­ë‚´)
# ===========================================
@st.cache_data(ttl=600)
def fetch_naver_news_api(query: str) -> List[Dict]:
    """ë„¤ì´ë²„ APIë¡œ êµ­ë‚´ ë‰´ìŠ¤ ìˆ˜ì§‘"""
    if "ë„¤ì´ë²„" in NAVER_CLIENT_ID or not NAVER_CLIENT_ID:
        return [{"ì œëª©": "âš ï¸ API í‚¤ ë¯¸ì„¤ì •: config.pyì— í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”.", "ë§í¬": "#", "ê²Œì‹œì¼": "", "ì–¸ë¡ ì‚¬": "ì‹œìŠ¤í…œ"}]

    url = "https://openapi.naver.com/v1/search/news.json"
    headers = {
        "X-Naver-Client-Id": NAVER_CLIENT_ID,
        "X-Naver-Client-Secret": NAVER_CLIENT_SECRET
    }
    params = {"query": query, "display": 10, "sort": "sim"}

    try:
        response = requests.get(url, headers=headers, params=params, timeout=10)
        if response.status_code == 200:
            items = response.json().get('items', [])
            results = []
            for item in items:
                clean_title = re.sub('<.*?>', '', item['title']).replace("&quot;", "'").replace("&amp;", "&")
                link = item.get('originallink') or item.get('link')
                pub_date = item.get('pubDate', '')[:16]
                
                results.append({
                    "ì œëª©": clean_title,
                    "ë§í¬": link,
                    "ê²Œì‹œì¼": pub_date,
                    "ì–¸ë¡ ì‚¬": "ë„¤ì´ë²„ë‰´ìŠ¤"
                })
            return results
        return [{"ì œëª©": f"âš ï¸ í†µì‹  ì˜¤ë¥˜ (Code: {response.status_code})", "ë§í¬": "#", "ê²Œì‹œì¼": "", "ì–¸ë¡ ì‚¬": "ì˜¤ë¥˜"}]
    except Exception as e:
        return [{"ì œëª©": f"âš ï¸ ì—ëŸ¬: {str(e)}", "ë§í¬": "#", "ê²Œì‹œì¼": "", "ì–¸ë¡ ì‚¬": "ì˜¤ë¥˜"}]


# ===========================================
# UI ì»´í¬ë„ŒíŠ¸
# ===========================================
def render_news_item(item: Dict, index: int, tab_key: str, show_summary: bool = True):
    """ë‰´ìŠ¤ í•­ëª© ë Œë”ë§ (ì´ë¯¸ì§€ ì œê±°, í…ìŠ¤íŠ¸ ì¤‘ì‹¬)"""
    with st.container():
        st.markdown(f"### {index + 1}. {item['ê°ì„±']} {item['ì œëª©']}")
        st.caption(f"{item['ê²Œì‹œì¼']}")
        
        # ì›ì œ í‘œì‹œ (ì˜ë¬¸ ê¸°ì‚¬ë§Œ)
        if 'ì›ì œ' in item:
            st.caption(f"ì›ì œ: _{item['ì›ì œ']}_")
        
        # ë²„íŠ¼ ì˜ì—­
        col_btn1, col_btn2, col_btn3 = st.columns([1, 1, 2])
        with col_btn1:
            st.link_button("ê¸°ì‚¬ ë³´ê¸°", item['ë§í¬'], use_container_width=True)
    
        
        st.divider()


def search_with_progress(search_func, label: str, *args, **kwargs):
    """ì‹¤ì‹œê°„ ì§„í–‰ë¥  í‘œì‹œì™€ í•¨ê»˜ ê²€ìƒ‰ ì‹¤í–‰"""
    progress_bar = st.progress(0)
    status_text = st.empty()
    
    # ë‹¨ê³„ 1: RSS íŒŒì‹±
    status_text.text(f"{label} - RSS í”¼ë“œ íŒŒì‹± ì¤‘...")
    progress_bar.progress(20)
    time.sleep(0.2)
    
    # ë‹¨ê³„ 2: ìˆ˜ì§‘ ì‹œì‘
    status_text.text(f"{label} - ë‰´ìŠ¤ ìˆ˜ì§‘ ë° í•„í„°ë§ ì¤‘...")
    progress_bar.progress(40)
    
    # ì‹¤ì œ ê²€ìƒ‰ ì‹¤í–‰
    results = search_func(*args, **kwargs)
    
    # ë‹¨ê³„ 3: ì²˜ë¦¬ ì™„ë£Œ
    progress_bar.progress(70)
    status_text.text(f"{label} - ë²ˆì—­ ë° ê°ì„± ë¶„ì„ ì™„ë£Œ ({len(results)}ê±´ ìˆ˜ì§‘)...")
    time.sleep(0.2)
    
    # ë‹¨ê³„ 4: ì™„ë£Œ
    progress_bar.progress(100)
    status_text.text(f"{label} - ê²€ìƒ‰ ì™„ë£Œ!")
    time.sleep(0.3)
    
    progress_bar.empty()
    status_text.empty()
    
    return results


# ===========================================
# ë©”ì¸ show() í•¨ìˆ˜
# ===========================================
def show():
    """ë‰´ìŠ¤ ì¸ì‚¬ì´íŠ¸ í˜ì´ì§€ë¥¼ ë Œë”ë§í•©ë‹ˆë‹¤."""
    
    st.markdown("<h1 style='text-align: center;'>ë‰´ìŠ¤ íë ˆì´ì…˜</h1>", unsafe_allow_html=True)
    st.markdown(" ")
    st.markdown(" ")
    st.markdown(" ")

    # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
    if 'risk_news' not in st.session_state:
        st.session_state['risk_news'] = []
    if 'origin_news' not in st.session_state:
        st.session_state['origin_news'] = []
    if 'korea_news' not in st.session_state:
        st.session_state['korea_news'] = []

    tab1, tab2, tab3 = st.tabs(["ê¸€ë¡œë²Œ ë¦¬ìŠ¤í¬", "ì‚°ì§€ë³„ ë™í–¥", "êµ­ë‚´ ì‹œì¥"])

    # ===========================================
    # Tab 1: ê¸€ë¡œë²Œ ë¦¬ìŠ¤í¬ (ë²„ê·¸ ìˆ˜ì •)
    # ===========================================
    with tab1:
        st.subheader("ê¸€ë¡œë²Œ ê³µê¸‰ë§ & ì •ì±… ë¦¬ìŠ¤í¬")
        st.markdown("EUDR ê·œì œ, í™í•´ ë¬¼ë¥˜ ìœ„ê¸°, ê³µê¸‰ë§ ë¦¬ìŠ¤í¬ ë“± ì»¤í”¼ ì‚°ì—…ì— ì˜í–¥ì„ ë¯¸ì¹˜ëŠ” ê¸€ë¡œë²Œ ì´ìŠˆë¥¼ ì¶”ì í•©ë‹ˆë‹¤.")
        
        if st.button("ë¦¬ìŠ¤í¬ ë‰´ìŠ¤ ê²€ìƒ‰", key="btn_risk", use_container_width=True):
            # ê²€ìƒ‰ ì¿¼ë¦¬ ë° í‚¤ì›Œë“œ ì •ì˜
            q = "Coffee Supply Chain OR EUDR Regulation OR Red Sea Logistics OR Coffee Price"
            targets = ["Coffee", "EUDR", "Red Sea", "Supply", "Logistics", "Price", "Regulation"]
            
            # ì§„í–‰ë¥  í‘œì‹œì™€ í•¨ê»˜ ê²€ìƒ‰ ì‹¤í–‰
            st.session_state['risk_news'] = search_with_progress(
                fetch_google_news, 
                "ê¸€ë¡œë²Œ ë¦¬ìŠ¤í¬",
                q, 
                targets, 
                period='365d'
            )
                
        if st.session_state['risk_news']:
            st.success(f"**ìµœì‹  ì»¤í”¼ ë‰´ìŠ¤ TOP {len(st.session_state['risk_news'][:10])}**")
            
            # ì›Œë“œí´ë¼ìš°ë“œ í‘œì‹œ
            with st.expander("í‚¤ì›Œë“œ ì›Œë“œí´ë¼ìš°ë“œ ë³´ê¸°"):
                display_wordcloud(st.session_state['risk_news'])
            
            st.divider()
            
            # ë‰´ìŠ¤ í•­ëª© í‘œì‹œ
            for i, item in enumerate(st.session_state['risk_news'][:10]):
                render_news_item(item, i, "risk", show_summary=True)

    # ===========================================
    # Tab 2: ì‚°ì§€ë³„ ë™í–¥ (ìš”ì•½ ê¸°ëŠ¥ ì œê±°)
    # ===========================================
    with tab2:
        st.subheader("ì£¼ìš” ì‚°ì§€ë³„ ë™í–¥")
        st.markdown("ë¸Œë¼ì§ˆ, ë² íŠ¸ë‚¨, ì½œë¡¬ë¹„ì•„ ë“± ì£¼ìš” ì»¤í”¼ ìƒì‚°êµ­ì˜ ìˆ˜í™•, ìˆ˜ì¶œ, ê°€ê²© ë™í–¥ì„ í™•ì¸í•©ë‹ˆë‹¤.")
        
        country = st.selectbox(
            "êµ­ê°€ ì„ íƒ", 
            ["Brazil", "Vietnam", "Colombia", "Ethiopia", "Indonesia", "Kenya"], 
            key="news_country"
        )
        
        def get_params(c):
            if c == "Vietnam":
                return '"Vietnam Coffee" (Export OR Production)', ["Vietnam", "Robusta", "Export"]
            elif c == "Brazil":
                return '"Brazil Coffee" (Harvest OR Export)', ["Brazil", "Arabica", "Harvest"]
            elif c == "Colombia":
                return '"Colombia Coffee" (Production OR Export)', ["Colombia", "Coffee"]
            elif c == "Ethiopia":
                return '"Ethiopia Coffee" (Export OR Production)', ["Ethiopia", "Coffee"]
            else:
                return f'"{c} Coffee" (Export OR Price)', [c, "Coffee"]

        if st.button(f"{country} ë‰´ìŠ¤ ê²€ìƒ‰", key="btn_origin", use_container_width=True):
            query, targets = get_params(country)
            st.session_state['origin_news'] = search_with_progress(
                fetch_google_news,
                f"{country} ì‚°ì§€ ë™í–¥",
                query, 
                targets, 
                period='90d'
            )
                
        if st.session_state['origin_news']:
            st.success(f"**ìµœì‹  ì»¤í”¼ ë‰´ìŠ¤ TOP {len(st.session_state['origin_news'][:10])}**")
            
            # ì›Œë“œí´ë¼ìš°ë“œ í‘œì‹œ
            with st.expander("í‚¤ì›Œë“œ ì›Œë“œí´ë¼ìš°ë“œ ë³´ê¸°"):
                display_wordcloud(st.session_state['origin_news'])
            
            st.divider()
            
            # ë‰´ìŠ¤ í•­ëª© í‘œì‹œ (ìš”ì•½ ê¸°ëŠ¥ ì œê±°)
            for i, item in enumerate(st.session_state['origin_news'][:10]):
                render_news_item(item, i, "origin", show_summary=False)

    # ===========================================
    # Tab 3: êµ­ë‚´ ë‰´ìŠ¤ (ë„¤ì´ë²„ API)
    # ===========================================
    with tab3:
        st.subheader("êµ­ë‚´ ì»¤í”¼ ì‹œì¥ & ì›ë‘ ë‰´ìŠ¤")
        st.markdown("ë„¤ì´ë²„ ê²€ìƒ‰ APIë¥¼ í™œìš©í•˜ì—¬ êµ­ë‚´ ì»¤í”¼ ì‹œì¥ì˜ ìµœì‹  ë™í–¥ì„ íŒŒì•…í•©ë‹ˆë‹¤.")
        
        if "ë„¤ì´ë²„" in NAVER_CLIENT_ID:
            st.warning("âš ï¸ ë„¤ì´ë²„ API í‚¤ê°€ ì…ë ¥ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. config.pyë¥¼ í™•ì¸í•˜ì„¸ìš”!")
        
        korea_keyword = st.radio(
            "ê´€ì‹¬ í‚¤ì›Œë“œ ì„ íƒ", 
            ["ì»¤í”¼ ì›ë‘ ê°€ê²©", "ìƒë‘ ìˆ˜ì…", "ì¹´í˜ ì°½ì—… ì‹œì¥", "ìŠ¤í˜ì…œí‹° ì»¤í”¼", "ì €ê°€ ì»¤í”¼ í”„ëœì°¨ì´ì¦ˆ"], 
            horizontal=True,
            key="korea_keyword"
        )
        
        if st.button("êµ­ë‚´ ë‰´ìŠ¤ ê²€ìƒ‰ (Naver API)", key="btn_korea", use_container_width=True):
            st.session_state['korea_news'] = search_with_progress(
                fetch_naver_news_api,
                "êµ­ë‚´ ë‰´ìŠ¤",
                korea_keyword
            )
                
        if st.session_state['korea_news']:
            st.success(f"**ìµœì‹  ì»¤í”¼ ë‰´ìŠ¤ TOP {len(st.session_state['korea_news'])}**")
            
            for i, item in enumerate(st.session_state['korea_news']):
                with st.container():
                    st.markdown(f"### {i + 1}. {item['ì œëª©']}")
                    st.caption(f"{item['ê²Œì‹œì¼']} | {item['ì–¸ë¡ ì‚¬']}")
                    st.link_button("ê¸°ì‚¬ ì›ë¬¸ ì½ê¸°", item['ë§í¬'], use_container_width=True)
                    st.divider()


if __name__ == "__main__":
    show()